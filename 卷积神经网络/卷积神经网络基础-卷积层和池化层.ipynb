{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "互相关运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19., 25.],\n",
      "        [37., 43.]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    H, W = X.shape\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros(H - h + 1, W - w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "Y = corr2d(X, K)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维卷积层\n",
    "\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏置来得到输出。卷积层的模型参数包括卷积核和标量偏置。\n",
    "\n",
    "torch.nn.Conv2d  模块采用F.conv2d实现\n",
    "下面来看一下F.con2d的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.nn.functional.conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层的简洁实现\n",
    "\n",
    "我们使用Pytorch中的`nn.Conv2d`类来实现二维卷积层，主要关注以下几个构造函数参数：\n",
    "\n",
    "* `in_channels` (python:int) – Number of channels in the input imag\n",
    "* `out_channels` (python:int) – Number of channels produced by the convolution\n",
    "* `kernel_size` (python:int or tuple) – Size of the convolving kernel\n",
    "* `stride` (python:int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "* `padding` (python:int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0\n",
    "* `bias` (bool, optional) – If True, adds a learnable bias to the output. Default: True\n",
    "\n",
    "`forward`函数的参数为一个四维张量，形状为$(N, C_{in}, H_{in}, W_{in})$，返回值也是一个四维张量，形状为$(N, C_{out}, H_{out}, W_{out})$，其中$N$是批量大小，$C, H, W$分别表示通道数、高度、宽度。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 12, 12])\n",
      "Y.shape:  torch.Size([4, 64, 10, 10])\n",
      "weight.shape:  torch.Size([64, 3, 3, 3])\n",
      "bias.shape:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(4, 3, 12, 12)\n",
    "print(X.shape)\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), stride=1, padding=0)\n",
    "Y = conv2d(X)\n",
    "print('Y.shape: ', Y.shape)  \n",
    "print('weight.shape: ', conv2d.weight.shape)\n",
    "print('bias.shape: ', conv2d.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 12, 12])\n",
      "max_Y.shape:  torch.Size([1, 1, 6, 6])\n",
      "avg_Y.shape:  torch.Size([1, 1, 6, 6])\n",
      "GAP_Y.shape: torch.Size([1, 1, 1, 1])\n",
      "X: tensor([[[[0.1988, 0.9745, 0.3511, 0.3418, 0.9431, 0.2993, 0.2055, 0.1830,\n",
      "           0.4065, 0.3654, 0.4467, 0.3732],\n",
      "          [0.0244, 0.7883, 0.1123, 0.5565, 0.3932, 0.6196, 0.9012, 0.6907,\n",
      "           0.9787, 0.1298, 0.6384, 0.4862],\n",
      "          [0.2284, 0.3182, 0.9082, 0.1801, 0.6586, 0.6051, 0.4111, 0.7285,\n",
      "           0.5617, 0.9079, 0.7297, 0.7224],\n",
      "          [0.7001, 0.2023, 0.3860, 0.5868, 0.7888, 0.3146, 0.0296, 0.2336,\n",
      "           0.0560, 0.3005, 0.1857, 0.3845],\n",
      "          [0.6650, 0.4888, 0.4619, 0.6912, 0.2414, 0.0063, 0.1162, 0.7385,\n",
      "           0.4623, 0.0897, 0.7672, 0.0788],\n",
      "          [0.5085, 0.4126, 0.0625, 0.7907, 0.2027, 0.2407, 0.1664, 0.3793,\n",
      "           0.5587, 0.9295, 0.3655, 0.0509],\n",
      "          [0.0314, 0.4190, 0.0533, 0.4610, 0.8633, 0.3946, 0.9353, 0.1005,\n",
      "           0.3189, 0.1677, 0.4112, 0.9544],\n",
      "          [0.2443, 0.9220, 0.4331, 0.8444, 0.2552, 0.3273, 0.5123, 0.4677,\n",
      "           0.1192, 0.3376, 0.1131, 0.7425],\n",
      "          [0.0764, 0.6684, 0.0319, 0.0101, 0.5666, 0.4415, 0.9678, 0.4167,\n",
      "           0.7648, 0.0982, 0.7025, 0.8279],\n",
      "          [0.5546, 0.6232, 0.1439, 0.9666, 0.7150, 0.1745, 0.0680, 0.4793,\n",
      "           0.5258, 0.4169, 0.8097, 0.7991],\n",
      "          [0.1183, 0.3876, 0.1392, 0.0212, 0.9972, 0.2126, 0.8162, 0.7811,\n",
      "           0.8639, 0.4153, 0.3572, 0.0499],\n",
      "          [0.0338, 0.1245, 0.4843, 0.3059, 0.1466, 0.9183, 0.3850, 0.4160,\n",
      "           0.2061, 0.7836, 0.3740, 0.6947]]]])\n",
      "Y: tensor([[[[0.9745, 0.5565, 0.9431, 0.9012, 0.9787, 0.6384],\n",
      "          [0.7001, 0.9082, 0.7888, 0.7285, 0.9079, 0.7297],\n",
      "          [0.6650, 0.7907, 0.2414, 0.7385, 0.9295, 0.7672],\n",
      "          [0.9220, 0.8444, 0.8633, 0.9353, 0.3376, 0.9544],\n",
      "          [0.6684, 0.9666, 0.7150, 0.9678, 0.7648, 0.8279],\n",
      "          [0.3876, 0.4843, 0.9972, 0.8162, 0.8639, 0.6947]]]])\n",
      "GAP_Y: tensor([[[[0.4467]]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 1, 12, 12)\n",
    "print(X.shape)\n",
    "maxpool2d=nn.MaxPool2d(2,stride=2)#最大池化\n",
    "\n",
    "avgpool2d=nn.AvgPool2d(2,stride=2)#平均池化\n",
    "\n",
    "GAP_Y=torch.nn.functional.adaptive_avg_pool2d(X,(1,1))#GAP\n",
    "\n",
    "max_Y=maxpool2d(X)\n",
    "\n",
    "avg_Y=avgpool2d(X)\n",
    "\n",
    "print('max_Y.shape: ', max_Y.shape)\n",
    "print('avg_Y.shape: ', avg_Y.shape)\n",
    "print(\"GAP_Y.shape:\",GAP_Y.shape)\n",
    "print(\"X:\",X)\n",
    "print(\"Y:\",max_Y)\n",
    "print(\"GAP_Y:\",GAP_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
